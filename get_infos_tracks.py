import pandas as pd
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
from tqdm import tqdm
import os
import time
import pickle
import concurrent.futures
from dotenv import load_dotenv

# ğŸ”¹ Chargement des variables d'environnement
load_dotenv()

# ğŸ”¹ Connexion Ã  l'API Spotify
client_id = os.getenv("CLIENT_ID")
client_secret = os.getenv("CLIENT_SECRET")
sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))

# ğŸ”¹ Cache pour stocker les rÃ©sultats et Ã©viter les appels rÃ©pÃ©tÃ©s
CACHE_FILE = "spotify_cache.pkl"
track_info_cache = {}
artist_info_cache = {}

def save_cache():
    with open(CACHE_FILE, "wb") as f:
        pickle.dump((track_info_cache, artist_info_cache), f)

def load_cache():
    global track_info_cache, artist_info_cache
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "rb") as f:
            track_info_cache, artist_info_cache = pickle.load(f)

# ğŸ”¹ Extraction automatique du **continent** et du **pays** Ã  partir du chemin du fichier
def extract_continent_and_country(file_path):
    parts = file_path.split(os.sep)
    if len(parts) >= 2:
        continent = parts[-2]
        filename = parts[-1]
        country = filename.split("_")[-1].replace(".csv", "")
        return continent, country
    return None, None

# ğŸ”¹ RÃ©cupÃ©ration des morceaux en batchs (50 par requÃªte)
def get_tracks_in_batches(batch_ids):
    while True:
        try:
            return sp.tracks(batch_ids)["tracks"]
        except spotipy.exceptions.SpotifyException as e:
            if e.http_status == 429:
                retry_after = int(e.headers.get("Retry-After", 5))
                print(f"âš ï¸ Rate limit atteint. Pause de {retry_after} secondes...")
                time.sleep(retry_after)
            else:
                print(f"âš ï¸ Erreur API : {e}")
                return []

# ğŸ”¹ RÃ©cupÃ©ration des infos des morceaux
def process_track(track, artist_name):
    if not track:
        return None
    try:
        track_id = track["id"]
        artist_id = track["artists"][0]["id"] if track["artists"] else None

        # ğŸ”¹ VÃ©rifie si l'info est dÃ©jÃ  en cache
        if track_id in track_info_cache:
            return track_info_cache[track_id]

        # ğŸ”¹ RÃ©cupÃ©ration des infos de l'artiste
        if artist_id in artist_info_cache:
            artist_info = artist_info_cache[artist_id]
        else:
            artist_info = sp.artist(artist_id) if artist_id else {"genres": [], "images": []}
            artist_info_cache[artist_id] = artist_info

        # ğŸ”¹ Nombre d'auditeurs mensuels (followers)
        monthly_listeners = artist_info["followers"]["total"]

        # ğŸ”¹ RÃ©cupÃ©ration des images
        track_image = track["album"]["images"][0]["url"] if track["album"]["images"] else None
        artist_image = artist_info["images"][0]["url"] if artist_info["images"] else None

        track_info = {
            "track_id": track_id,
            "popularity": track["popularity"],
            "duration_ms": track["duration_ms"],
            "explicit": track["explicit"],
            "genre": artist_info["genres"][0] if artist_info["genres"] else None,
            "release_date": track["album"]["release_date"],
            "track_image": track_image,
            "artist_image": artist_image,
            "monthly_listeners": monthly_listeners
        }

        # ğŸ”¹ Ajoute au cache
        track_info_cache[track_id] = track_info
        return track_info

    except Exception as e:
        print(f"âš ï¸ Erreur lors du traitement d'un morceau : {e}")
        return None

# ğŸ”¹ RÃ©cupÃ¨re les informations pour plusieurs morceaux
def get_tracks_info(track_ids, artist_names):
    track_data = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = []
        for i in range(0, len(track_ids), 50):
            batch_ids = track_ids[i:i+50]
            futures.append(executor.submit(get_tracks_in_batches, batch_ids))

        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc="ğŸ” RÃ©cupÃ©ration des morceaux"):
            tracks = future.result()
            for track, artist_name in zip(tracks, artist_names[i:i+50]):
                track_info = process_track(track, artist_name)
                if track_info:
                    track_data.append(track_info)

    return pd.DataFrame(track_data)

# ğŸ”¹ Enrichissement des fichiers CSV
def enrich_multiple_csv_with_spotify_data(input_files, output_base_folder):
    if not os.path.exists(output_base_folder):
        os.makedirs(output_base_folder)

    for input_file in input_files:
        continent, country = extract_continent_and_country(input_file)
        if not continent or not country:
            print(f"âŒ Impossible d'extraire les informations du fichier {input_file}")
            continue

        # ğŸ”¹ CrÃ©ation des dossiers automatiquement
        output_folder = os.path.join(output_base_folder, continent)
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)

        output_file = os.path.join(output_folder, f"charts_{country}.csv")
        print(f"ğŸ“¥ Traitement du fichier : {input_file}")

        df = pd.read_csv(input_file)

        if 'track_id' not in df.columns or 'artist_names' not in df.columns:
            print(f"âŒ Colonnes manquantes dans {input_file}")
            continue

        track_ids = df["track_id"].unique()
        artist_names = df["artist_names"].tolist()

        print(f"ğŸ” RÃ©cupÃ©ration des donnÃ©es Spotify pour {len(track_ids)} morceaux...")

        df_spotify = get_tracks_info(track_ids, artist_names)
        if df_spotify.empty:
            print(f"âŒ Ã‰chec de rÃ©cupÃ©ration des donnÃ©es pour {input_file}.")
            continue

        df_merged = df.merge(df_spotify, on="track_id", how="left")
        df_merged.to_csv(output_file, index=False)
        print(f"âœ… Fichier enrichi {output_file} crÃ©Ã© avec succÃ¨s !")

        # ğŸ”¹ Sauvegarde du cache aprÃ¨s chaque fichier
        save_cache()

# ğŸ”¹ Exemple d'utilisation
if __name__ == "__main__":
    input_files = [
        "Charts_no_info/Charts_North_America/charts_CANğŸ‡¨ğŸ‡¦.csv",
        "Charts_no_info/Charts_North_America/charts_USAğŸ‡ºğŸ‡¸.csv",
        "Charts_no_info/Charts_North_America/charts_MEXğŸ‡²ğŸ‡½.csv",

        "Charts_no_info/Charts_Asia/charts_AREğŸ‡¦ğŸ‡ª.csv",
        "Charts_no_info/Charts_Asia/charts_IDNğŸ‡®ğŸ‡©.csv",
        "Charts_no_info/Charts_Asia/charts_INDğŸ‡®ğŸ‡³.csv",
        "Charts_no_info/Charts_Asia/charts_JPNğŸ‡¯ğŸ‡µ.csv",
        "Charts_no_info/Charts_Asia/charts_KORğŸ‡°ğŸ‡·.csv",
        "Charts_no_info/Charts_Asia/charts_SAUğŸ‡¸ğŸ‡¦.csv",
        "Charts_no_info/Charts_Asia/charts_THAğŸ‡¹ğŸ‡­.csv",
        "Charts_no_info/Charts_Asia/charts_TURğŸ‡¹ğŸ‡·.csv",

        "Charts_no_info/Charts_Europe/charts_BELğŸ‡§ğŸ‡ª.csv",
        "Charts_no_info/Charts_Europe/charts_DNKğŸ‡©ğŸ‡°.csv",
        "Charts_no_info/Charts_Europe/charts_ESPğŸ‡ªğŸ‡¸.csv",
        "Charts_no_info/Charts_Europe/charts_FINğŸ‡«ğŸ‡®.csv",
        "Charts_no_info/Charts_Europe/charts_FRAğŸ‡«ğŸ‡·.csv",
        "Charts_no_info/Charts_Europe/charts_GBRğŸ‡¬ğŸ‡§.csv",
        "Charts_no_info/Charts_Europe/charts_ITAğŸ‡®ğŸ‡¹.csv",
        "Charts_no_info/Charts_Europe/charts_NORğŸ‡³ğŸ‡´.csv",

        "Charts_no_info/Charts_Oceania/charts_AUSğŸ‡¦ğŸ‡º.csv",
        "Charts_no_info/Charts_Oceania/charts_NZLğŸ‡³ğŸ‡¿.csv",

        "Charts_no_info/Charts_South_America/charts_ARGğŸ‡¦ğŸ‡·.csv",
        "Charts_no_info/Charts_South_America/charts_BOLğŸ‡§ğŸ‡´.csv",
        "Charts_no_info/Charts_South_America/charts_BRAğŸ‡§ğŸ‡·.csv",
        "Charts_no_info/Charts_South_America/charts_CHLğŸ‡¨ğŸ‡±.csv",
        "Charts_no_info/Charts_South_America/charts_COLğŸ‡¨ğŸ‡´.csv",
        "Charts_no_info/Charts_South_America/charts_VENğŸ‡»ğŸ‡ª.csv",

        "Charts_no_info/Charts_Africa/charts_EGYğŸ‡ªğŸ‡¬.csv",
        "Charts_no_info/Charts_Africa/charts_MARğŸ‡²ğŸ‡¦.csv",
        "Charts_no_info/Charts_Africa/charts_NGAğŸ‡³ğŸ‡¬.csv",
        "Charts_no_info/Charts_Africa/charts_ZAFğŸ‡¿ğŸ‡¦.csv",
    ]
    output_folder = "Charts_with_info"
    load_cache()
    enrich_multiple_csv_with_spotify_data(input_files, output_folder)
